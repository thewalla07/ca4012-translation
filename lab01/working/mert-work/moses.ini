# MERT optimized configuration
# decoder /usr/local/mosesdecoder/bin/moses
# BLEU 0.128631 on dev /users/case4/wallm22/smt-lab/corpus/tune-data.fr
# We were before running iteration 4
# finished Tue  7 Feb 13:35:34 GMT 2017
### MOSES CONFIG FILE ###
#########################

# input factors
[input-factors]
0

# mapping steps
[mapping]
0 T 0

[distortion-limit]
6

# feature functions
[feature]
UnknownWordPenalty
WordPenalty
PhrasePenalty
PhraseDictionaryMemory name=TranslationModel0 table-limit=20 num-features=4 path=/users/case4/wallm22/smt-lab/working/train/model/phrase-table.gz input-factor=0 output-factor=0
LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/users/case4/wallm22/smt-lab/working/train/model/reordering-table.wbe-msd-bidirectional-fe.gz
Distortion
KENLM lazyken=0 name=LM0 factor=0 path=/users/case4/wallm22/smt-lab/lm/lm.arpa.en order=3

# dense weights for feature functions
[weight]

LexicalReordering0= 0.0784406 0.270514 0.0653735 0.16017 -0.070337 -0.0280092
Distortion0= 0.0455318
LM0= 0.0474708
WordPenalty0= -0.0533124
PhrasePenalty0= 0.0523121
TranslationModel0= 0.0447257 0.04577 -0.0132907 0.0247419
